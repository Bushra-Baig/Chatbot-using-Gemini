{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U langgraph langsmith langchain langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "id": "RTXV3I61B2B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE_API_KEY\"  # Replace with your Gemini API key"
      ],
      "metadata": {
        "id": "91ZNFG5pCLrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Define the state\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Initialize Gemini 2.0 Flash LLM\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "\n",
        "# Build the LangGraph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# You would add LLM logic here as a node later\n",
        "# Example:\n",
        "# graph_builder.add_node(\"gemini_node\", some_function_that_calls_llm)"
      ],
      "metadata": {
        "id": "Nwtr5vH-CVtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "import os\n",
        "\n",
        "# âœ… Define the state structure\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# âœ… Initialize the LLM with Gemini 2.0 Flash\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "\n",
        "# âœ… Define the chatbot function for the graph node\n",
        "def chatbot(state: State) -> dict:\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# âœ… Build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "id": "RTnlhvxsCiAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install dependencies (run only once)\n",
        "!pip install -U langchain langgraph langchain-google-genai\n",
        "\n",
        "# âœ… Import necessary packages\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langchain_core.messages import HumanMessage\n",
        "import getpass\n",
        "\n",
        "# âœ… Securely enter your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"ğŸ” Enter your Gemini API key: \")\n",
        "\n",
        "# âœ… Define conversation state\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# âœ… Initialize Gemini 2.0 Flash model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "\n",
        "# âœ… Define chatbot behavior\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# âœ… Build LangGraph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# âœ… Function to stream Gemini chat\n",
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [HumanMessage(content=user_input)]}):\n",
        "        for value in event.values():\n",
        "            print(\"ğŸ¤– Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "# âœ… Start interactive chat\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"ğŸ§‘ You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"ğŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except Exception as e:\n",
        "        print(\"âš  Error:\", e)\n",
        "        break"
      ],
      "metadata": {
        "id": "7qlGrzIYDVeD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}